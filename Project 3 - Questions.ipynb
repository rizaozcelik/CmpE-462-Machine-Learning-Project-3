{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPE 462 - Project 3\n",
    "## Logistic Matrix Factorization\n",
    "\n",
    "**Student IDs:**\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "Binary matrices (Matrices with elements of 0/1) appear in many applications. A binary matrix can represent relations such as 'User $i$ bought item $j$', or 'Member $i$ likes Member $j$'. Such datasets are often sparse -- only a fraction of the possible entries of a matrix are known. \n",
    "\n",
    "A binary matrix can also viewed as the adjacency matrix of a bipartite graph. Hence each entry corresponds to an edge.\n",
    "One task here is known as link prediction, meaning guessing the presence or absence of edges in the underlying graph. \n",
    "This prediction can then be used for several tasks such as recommendation or knowledge-base completion.\n",
    "\n",
    "In this project, you are going to implement a matrix factorization with missing elements using Stochastic Gradient Descent (SGD), Batch SGD and GD first in numpy, then also making use of PyTorch. You will also analyze the effect of the fraction of missing elements, estimation rank and max iteration. \n",
    "\n",
    "The matrix you will factorize is a binary(logistic) matrix and has a specific pattern. Its elements that whose indices sum up to an even number are 1 and 0 otherwise. For more detailed derivation and problem description, you can analyze [this](https://github.com/atcemgil/notes/blob/master/Logistic%20Matrix%20Factorization.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1./(1+np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "\n",
    "This cell generates the dataset as we have discussed. It sets the elements whom indices sum up to even number to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 50 # Use a square matrix of 50x50. You can change it if you wish\n",
    "original_matrix = np.array([[int((i + j) % 2 == 0) for j in range(M)] for  i in range(M)])\n",
    "plt.imshow(original_matrix, interpolation='nearest')  \n",
    "plt.title('Original Matrix (Full data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking\n",
    "\n",
    "Now mask the dataset. Number of elements to mask is set by a parameter. \n",
    "\n",
    "Seed the random for repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "def generate_mask(M = 50, mask_count=M*M//10):\n",
    "    masks = [(random.randint(0,M-1), random.randint(0,M-1)) for i in range(mask_count)]\n",
    "    mask = np.ones((M,M))\n",
    "    for m in masks:\n",
    "        mask[m] = np.nan\n",
    "    return mask\n",
    "\n",
    "mask = generate_mask(M)\n",
    "plt.imshow(mask, interpolation='nearest')  \n",
    "plt.title('Masked Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descents\n",
    "\n",
    "Implement **SGD**. **BGD** and **GD** in this cell using **numpy**. Compute the error of the resulting matrix compared to original data for approximation ranks in [1,M]. For measuring the quality of the fit, you should use the log-likelihood\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\log p(Y |W, H ) &=& \\sum_j \\sum_{i} M(i,j) Y(i,j) \\left(\\sum_k W(i,k) H(k,j)\\right)  - \\sum_j \\sum_{i} M(i,j) \\log\\left( 1+ \\exp\\left(\\sum_k W(i,k) H(k,j)\\right)\\right) \n",
    "\\end{eqnarray}\n",
    "\n",
    "For plot generation, use results computed by SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement SGD here. Add the method signatures for other gradient descents as well. You can add a batch size parameter to merge\n",
    "# all types of gradient descents into one method.\n",
    "def sgd(original_matrix, mask, estimation_rank, MAX_ITER=10000,eta=0.005, nu=0.1):\n",
    "    pass\n",
    "# Compute error for varying estimation ranks from 1 to M\n",
    "errors = [] # store the error to this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot error vs estimation rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,M), errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute error for both changing rank( 1 to M) and max_iter(5000-20000). Plot it as a heatmap. You can use the plotting code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(errors, cmap='hot', interpolation='nearest', extent=[5000,20000,1,M], aspect='auto')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Approximation Rank')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze the effect of varying the hidden element count(set your own limits) and approximation rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(errors, cmap='hot', interpolation='nearest', extent=[250,2500,1,50], aspect='auto')\n",
    "plt.xlabel('Mask Count')\n",
    "plt.ylabel('Approximation Rank')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Now implement BGD and SGD using PyTorch and generate the same plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
